{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file _concrete_data_week3.zip_ appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder _concrete_data_week3_ appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: _train_ and _valid_. And if you explore these folders, you will find that each contains two subfolders: _positive_ and _negative_. These are the same folders that we saw in the labs in the previous modules of this course, where _negative_ is the negative class and it represents the concrete images with no cracks and _positive_ is the positive class and it represents the concrete images with cracks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the _negative_ and _positive_ folders. This may consume all of your memory and you may end up with a **50\\*** error. So please **DO NOT DO IT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1.  We are obviously dealing with two classes, so _num_classes_ is 2. \n",
    "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3.  We will training and validating the model using batches of 100 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to _preprocess_input_ which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the _flow_from_directory_ method to get the training images as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the _flow_from_directory_ method to get the validation images and assign the result to **validation_generator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument _include_top_ and set it to **False**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the _layers_ attribute of our model object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.Functional at 0x1435afdf0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x143a82e50>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x142efac10>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x142efad90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x142f14340>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x142f14910>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x142f76040>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x142f764f0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x142f763a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x142fee100>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x142ff4b50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1430063a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143006580>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143013f70>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14301cb20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x142f9a0a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14301cd30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x142f9a430>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14302e8b0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143041310>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1430416d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143041c10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143041790>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143061070>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143061190>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143069b50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143079730>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143079bb0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1430864c0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x14309c190>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14309c2e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14309c250>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1430a02b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1430b3a30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1430b3d60>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1430bc070>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1430d5250>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1430d56d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14250e430>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1424cc520>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1424e5c10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x13b414b50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143026520>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14310aaf0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143115040>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1431191c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1431153a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1424e5580>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14312c910>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1424e5e50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14313b2e0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143143d90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14314e190>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14314e790>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14315b9d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143166a30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143166d60>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14316e070>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143189220>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1431896a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143193dc0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x14319d9d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14319dcd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1431a9700>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1431b9ee0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1431c3550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1431c3760>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1431d0250>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1431dad90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1431dafd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1431eb040>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1431fd520>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1431fd8e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1431fde20>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143208130>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14321e070>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14321e280>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14321e370>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143237850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143237a60>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1432445e0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143259070>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143259430>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143270be0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143270520>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143294040>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143294160>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1432982e0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1432ab700>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1432593a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1432abb80>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14325fd30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1432b7490>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1432cc0a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1432cc2e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1432cc8e0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1432d8af0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1432e6b50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1432e6e80>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1432f4760>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1433083a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143308820>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143311f10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x14331cb50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14331ce50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143326880>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143326130>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1433436d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1433438e0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14334c3d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143363100>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143363340>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1433681c0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x14337a670>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14337aa30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14337adc0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1433819a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14339c1c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14339c3d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14339c4c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1433b19d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1433b1be0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1433bbca0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1433d61c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1433d6580>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1433d6ac0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1433db550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1433ebcd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1433ebee0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1433fb0a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1434104c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143410940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14341b6d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143425c70>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143425f70>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1434300d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143430fa0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14344a7c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14344aaf0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434533d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14346b100>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14346b430>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434722b0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143483760>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143483b20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1434a5310>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434a5c40>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1434ba670>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1434ba850>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434cb250>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1434d3e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143483a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1434de340>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14348ca90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434e7160>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1434f8610>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1434f89d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1434f8eb0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1434f8a90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14351a280>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14351a490>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14351a580>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x143530a30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143530c40>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143539d00>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x143554220>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1435545e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x143554b20>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14355a5b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14356bdc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1435741c0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14357c100>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x14358d520>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14358d9a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x143598220>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x1435a4cd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x1435a4fd0>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x1434f8e20>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the _summary_ attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-172e67583a70>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "301/301 [==============================] - 3625s 12s/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 3710s 12s/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file _classifier_resnet_model.h5_ apprear in the left directory pane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called _AI Capstone Project with Deep Learning_. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
    "| 2020-09-18        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright © 2020 [IBM Developer Skills Network](https://cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
